{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Untick/resume-builder-gr1/blob/main/Zabigullin%20Vadim/%D0%9F%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BA%D0%B0_%D0%BF%D1%80%D0%B0%D0%B2%D0%BE%D0%BF%D0%B8%D1%81%D0%B0%D0%BD%D0%B8%D1%8F_%D0%B2_%D1%80%D0%B5%D0%B7%D1%8E%D0%BC%D0%B5_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обращение к ChatGPT по API. Роли. Влияние инструкции на ответ модели."
      ],
      "metadata": {
        "id": "XBvl4SBcTXzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Языковые модели, такие как GPT, создаются компанией OpenAI, и с каждой новой версией (от GPT-1 до последней, GPT-4), модель становится всё более мощной и точной. Это означает, что она может создавать более качественные и разнообразные тексты на основе предоставленного вами ввода.\n",
        "\n",
        "Если вы используете платную подписку **ChatGPT Plus**, у вас есть доступ к моделям GPT-3.5 и GPT-4. Это позволяет вам выбирать модель, которая наилучшим образом подходит для ваших нужд, в зависимости от конкретного применения. Например, GPT-4 может быть более полезен для более сложных задач, требующих более точного понимания и генерации текста.\n",
        "\n",
        "Через API OpenAI вы можете получить доступ к большему количеству моделей, хотя некоторые из них являются старыми версиями. Доступ к GPT-4 через API предоставляется только после одобрения OpenAI, поскольку это наиболее мощная модель и ее использование может потребовать большего контроля и ресурсов.\n",
        "\n",
        "Для большинства пользователей API наиболее подходящей и экономичной моделью будет gpt-3.5-turbo. Она предлагает оптимальное сочетание стоимости и производительности, что делает ее хорошим выбором для большинства приложений.\n",
        "\n",
        "Важно помнить о токенах при использовании этих моделей. Токены - это единицы текста, которые модель обрабатывает при каждом запросе. Количество токенов, используемых в каждом запросе, влияет на стоимость использования модели. Более длинные тексты потребуют больше токенов, и следовательно, будут стоить больше. Поэтому очень важно контролировать использование токенов, особенно при работе с большими объемами данных или при выполнении большого количества запросов. Это особенно важно при использовании GPT-4, поскольку эта модель может быстро исчерпать ваш бюджет. К подсчету токенов мы еще вернемся в данном занятии.\n",
        "\n",
        "Давайте посмотрим, как обращаться к GPT через API.\n",
        "\n",
        "Конечно же, для работы с GPT через API вам необходимо получить API ключ. Подробная инструкция, как подключиться к ChatGPT из России и оплатить использование GPT по API находится тут: https://docs.google.com/document/d/1Xnzx8Ve0gncUQREnnGMEa2IukNmYqZp0wD_3PTpWZSM/edit?usp=sharing"
      ],
      "metadata": {
        "id": "Hy2vEIToHgnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "C-wmZc1NgWtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e028d7-6d09-496b-d303-01b659b77307"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m801.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, как можно взаимодействовать с моделью общения OpenAI (в данном случае, \"gpt-3.5-turbo\") через их API. Передадим сообщение в модель и попросим ее сгенерировать ответ.\n",
        "\n",
        "ChatGPT использует концепцию \"ролей\" для различных участников в диалоге.\n",
        "Каждое сообщение в списке messages является словарем, имеющим два поля: role и content. Role может принимать одно из трех значений: \"system\", \"user\" или \"assistant\", указывая, кто именно \"говорит\" сообщение. Content содержит само сообщение.\n",
        "\n",
        " В стандартном случае, три основные роли могут быть включены в чат:\n",
        "\n",
        "* **\"system\"**: Системная роль используется для установки контекста диалога. Это как общая инструкция для модели, которая определяет её поведение во время диалога. Сообщения от \"system\" обычно помещаются в начале диалога и могут содержать информацию, как модель должна вести себя в роли ассистента.\n",
        "\n",
        "* **\"user\"**: Это роль для человека- пользователя, который ведет диалог с моделью. Ваши запросы к модели будут выставлены под этой ролью.\n",
        "\n",
        "* **\"assistant\"**: Это роль для модели AI, которая отвечает на запросы от пользователя.\n",
        "\n",
        "При создании чата с моделью, вы предоставляете список сообщений. Каждое сообщение в этом списке — это словарь, содержащий два элемента: \"role\" и \"content\". \"Role\" указывает на роль (вышеупомянутые \"system\", \"user\" или \"assistant\"), а \"content\" содержит фактический текст сообщения."
      ],
      "metadata": {
        "id": "qp0va4yIP4-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import openai\n",
        "import os\n",
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key\n"
      ],
      "metadata": {
        "id": "j4abwqc9Wo4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99958fa-4c8c-409b-f8d0-c09012d3c06d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала, создадим переменные, в которых будут находится тексты, которые мы будем подавать в system и user:"
      ],
      "metadata": {
        "id": "zf9x9tIUVPpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system = '''Ты опытный и старательный специалист-лингвист, который занимается коррекцией ошибок в резюме соискателей работы в области разработки искусственного интеллекта, написанных русским текстом.\n",
        "У тебя есть инструкция, в которой описано как правильно делать коррекцию русского текста. Тебе предоставят текст, скорректируй его, если это необходимо, опираясь на эту инструкцию.\n",
        "Корректируй текст максимально точно по инструкции. Не упоминай инструкцию и примеры текста из неё при ответе. Построй грамматически правильно предложение и исправь все ошибки в нём.\n",
        "Например такой текст: \"Каторая на стале калбаса сьела нихарошая лижала сабака ее\" после исправления должен быть таким:\n",
        "\"Нехорошая собака съела её колбасу, которая лежала на столе\".'''\n",
        "\n",
        "base_info= '''Понимание задачи: Перед началом работы удостоверьтесь, что вы понимаете контекст и цель текста. Это поможет вам правильно интерпретировать предложения и выявить ошибки.\n",
        "Проверка орфографии: Внимательно проверьте орфографию слов. Обратите внимание на правильность написания букв, прописных и строчных букв, использование буквы ё и другие орфографические правила.\n",
        "Проверка пунктуации: Убедитесь, что пунктуация в тексте соответствует правилам. Проверьте запятые, точки, тире, кавычки и другие знаки препинания.\n",
        "Согласование времен и лиц: Проверьте согласование времен и лиц в предложениях. Убедитесь, что временные формы глаголов и лица согласованы.\n",
        "Проверка синтаксиса: Проверьте структуру предложений и их логическую связь. Устраните ошибки, связанные с неправильным порядком слов или непонятной структурой предложений.\n",
        "Проверка согласования: Удостоверьтесь, что существительные, прилагательные и глаголы согласованы в роде, числе и падеже.\n",
        "Использование словарей и справочников: Пользуйся словарями, доступными тебе, стилистическими справочниками и грамматическими ресурсами для подтверждения правильности исправлений.\n",
        "Связность и структура: Обратите внимание на связность текста и его общую структуру. Убедитесь, что переходы между абзацами и идеями логичны.\n",
        "Контроль за повторами: Проверьте текст на повторяющиеся слова, фразы или идеи и устраните их, если это необходимо.\n",
        "Проверка стиля и тона: Учтите стиль и тональность текста в соответствии с его назначением. В случае необходимости, предложите исправления, чтобы улучшить стиль и язык текста.\n",
        "Финальное чтение: После всех исправлений выполните финальное чтение текста для проверки, что все ошибки были устранены и текст готов к публикации.'''\n",
        "\n",
        "#question = '''Я на поле по тракттаре еххал'''\n",
        "#question = '''утюг включить как подробная тут инструкция'''  # Подробная инструкция, как включить утюг, находится тут\n",
        "#question = '''програмист я опыттныйй со стажемм роботы больше чем читыре года'''\n",
        "question = '''Праграмист я опыттныйй со стажемм роботы больше чем читыре года. Маи навыки в програмирование такиее имеються как знаю харашо питон, ява, и си плюс плюс'''"
      ],
      "metadata": {
        "id": "TiJw2r8-B05K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3IFavkZvdY8",
        "outputId": "c4b9c991-0712-488d-f961-7c3f8e746835"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "KmlUiYsHWq9j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
        "    \"\"\"Возвращает количество токенов, используемых списком сообщений.\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model) # Пытаемся получить кодировку для выбранной модели\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\") # если не получается, используем кодировку \"cl100k_base\"\n",
        "    if model == \"gpt-3.5-turbo-0301\" or \"gpt-3.5-turbo-0613\" or \"gpt-3.5-turbo-16k\" or \"gpt-3.5-turbo\":\n",
        "        num_tokens = 0 # начальное значение счетчика токенов\n",
        "        for message in messages: # Проходимся по каждому сообщению в списке сообщений\n",
        "            num_tokens += 4  # каждое сообщение следует за <im_start>{role/name}\\n{content}<im_end>\\n, что равно 4 токенам\n",
        "            for key, value in message.items(): # итерация по элементам сообщения (роль, имя, контент)\n",
        "                num_tokens += len(encoding.encode(value)) # подсчет токенов в каждом элементе\n",
        "                if key == \"name\":  # если присутствует имя, роль опускается\n",
        "                    num_tokens += -1  # роль всегда требуется и всегда занимает 1 токен, так что мы вычитаем его, если имя присутствует\n",
        "        num_tokens += 2  # каждый ответ начинается с <im_start>assistant, что добавляет еще 2 токена\n",
        "        return num_tokens # возвращаем общее количество токенов\n",
        "    else:\n",
        "      # Если выбранная модель не поддерживается, генерируем исключение\n",
        "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}. # вызываем ошибку, если функция не реализована для конкретной модели\"\"\")\n"
      ],
      "metadata": {
        "id": "0V8d7uA1MOKh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка правописания"
      ],
      "metadata": {
        "id": "x6Bdi2vdfbJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# корявый текст\n",
        "question = '''Праграмист я опыттныйй со стажемм роботы больше чем читыре года. Маи навыки в програмирование такиее имеються как питон, ява, майСКЛ и си плюс плюс'''"
      ],
      "metadata": {
        "id": "W7CvXJVVTMiS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# текст скоррекированный ChatGPT\n",
        "messages = [\n",
        "      {\"role\": \"system\", \"content\": system},\n",
        "      {\"role\": \"user\", \"content\": base_info+ f\"{question}\" }\n",
        "      #{\"role\": \"user\", \"content\": question}\n",
        "      ]\n",
        "\n",
        "print(f\"{num_tokens_from_messages(messages, 'gpt-3.5-turbo-0301')} токенов использовано на вопрос\")\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.0,\n",
        "    max_tokens=1000\n",
        "    )\n",
        "print(completion)\n",
        "message = completion['choices'][0]['message']['content']\n",
        "print(\"Мой текст:\", question)\n",
        "print(\"Текст скоррекированный ChatGPT:\", message)"
      ],
      "metadata": {
        "id": "ZmTdl1R6Wq_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975883b4-0d3e-4abd-b664-60c9b84e4ef6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1094 токенов использовано на вопрос\n",
            "{\n",
            "  \"id\": \"chatcmpl-7r2oLOTJTiOJufL92hqJN8irU7mii\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1692876545,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\u042f \\u043e\\u043f\\u044b\\u0442\\u043d\\u044b\\u0439 \\u043f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0441\\u0442 \\u0441 \\u043e\\u043f\\u044b\\u0442\\u043e\\u043c \\u0440\\u0430\\u0431\\u043e\\u0442\\u044b \\u0431\\u043e\\u043b\\u0435\\u0435 \\u0447\\u0435\\u0442\\u044b\\u0440\\u0435\\u0445 \\u043b\\u0435\\u0442. \\u0423 \\u043c\\u0435\\u043d\\u044f \\u0435\\u0441\\u0442\\u044c \\u043d\\u0430\\u0432\\u044b\\u043a\\u0438 \\u043f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043d\\u0430 Python, Java, MySQL \\u0438 C++.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1093,\n",
            "    \"completion_tokens\": 43,\n",
            "    \"total_tokens\": 1136\n",
            "  }\n",
            "}\n",
            "Мой текст: Праграмист я опыттныйй со стажемм роботы больше чем читыре года. Маи навыки в програмирование такиее имеються как питон, ява, майСКЛ и си плюс плюс\n",
            "Текст скоррекированный ChatGPT: Я опытный программист с опытом работы более четырех лет. У меня есть навыки программирования на Python, Java, MySQL и C++.\n"
          ]
        }
      ]
    }
  ]
}