{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [КОД-1. Подготовка](#toc1_)    \n",
    "    - [Импортируем библиотеку importlib](#toc1_1_1_)    \n",
    "    - [Импортируем модуль 'tiktoken'](#toc1_1_2_)    \n",
    "    - [Импорт необходимых модулей](#toc1_1_3_)    \n",
    "    - [Для начала, создадим переменные, в которых будут находится тексты, которые мы будем подавать в system и user:](#toc1_1_4_)    \n",
    "    - [System: От имени кого нужно работать с текстом](#toc1_1_5_)    \n",
    "    - [base_info](#toc1_1_6_)    \n",
    "- [Задаем переменные: question и assist](#toc2_)    \n",
    "- [КОД-2. Проверка количества токенов и исправление ошибок](#toc3_)    \n",
    "  - [Проверяем количество токенов](#toc3_1_)    \n",
    "  - [Проверка правописания](#toc3_2_)    \n",
    "      - [Вариант 2. Новичок](#toc3_2_1_1_)    \n",
    "      - [Вариант 3 / Опытный программист](#toc3_2_1_2_)    \n",
    "      - [Вариант 1-2 / temperature=1 / без assistant](#toc3_2_1_3_)    \n",
    "      - [Вариант 2-2 / temperature=1 / Наинающий программист](#toc3_2_1_4_)    \n",
    "      - [Вариант 3-2 / temperature=1 / Опытный программист](#toc3_2_1_5_)    \n",
    "- [Код с различными параметрами assistant и temperature оборачиваем в функции](#toc4_)    \n",
    "- [Работа функций](#toc5_)    \n",
    "    - [Assistant = NO / Temperature = 0.5](#toc5_1_1_)    \n",
    "    - [Assistant = Начинающий специалист ... / Temperature = 0.5](#toc5_1_2_)    \n",
    "    - [Assistant = Опытный инженер-программист ... / Temperature = 0.5](#toc5_1_3_)    \n",
    "    - [Assistant = NO / Temperature = 1](#toc5_1_4_)    \n",
    "    - [Assistant = Начинающий специалист ... / Temperature = 1](#toc5_1_5_)    \n",
    "    - [Assistant = Опытный инженер-программист ... / Temperature = 1](#toc5_1_6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[КОД-1. Подготовка](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Импортируем библиотеку importlib](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модуль \"openai\" установлен ранее.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Пытаемся импортировать модуль 'openai'\n",
    "try:\n",
    "    importlib.import_module('openai')\n",
    "    print('Модуль \"openai\" установлен ранее.')\n",
    "# Если импорт не удался, устанавливаем модуль 'openai' с помощью pip\n",
    "except ImportError:\n",
    "    !pip install openai\n",
    "    print('Модуль \"openai\" установлен.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Импортируем модуль 'tiktoken'](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модуль \"tiktoken\" установлен ранее.\n"
     ]
    }
   ],
   "source": [
    "# Пытаемся импортировать модуль 'tiktoken'\n",
    "try:\n",
    "    importlib.import_module('tiktoken')\n",
    "    print('Модуль \"tiktoken\" установлен ранее.')\n",
    "# Если импорт не удался, устанавливаем модуль 'tiktoken' с помощью pip\n",
    "except ImportError:\n",
    "    !pip install tiktoken\n",
    "    print('Модуль \"tiktoken\" установлен.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Импорт необходимых модулей](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import openai\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение ключа API от пользователя и установка его как переменной окружения\n",
    "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_4_'></a>[Для начала, создадим переменные, в которых будут находится тексты, которые мы будем подавать в system и user:](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_5_'></a>[System: От имени кого нужно работать с текстом](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это пока лучшая инструкция\n",
    "\n",
    "system = '''Ты являешься опытным и добросовестным лингвистом, специализирующимся на коррекции резюме соискателей, работающих в области разработки искусственного интеллекта на русском языке.\n",
    "У тебя имеется подробная инструкция, которая описывает, как правильно выполнять коррекцию русского текста. Тебе предоставят текст, и в случае необходимости, ты будешь вносить исправления, соблюдая данную инструкцию.\n",
    "Ты стремишся максимально точно исправлять текст в соответствии с инструкцией, не упоминая при этом саму инструкцию и примеры из неё. Твоей целью является построение грамматически верных предложений,\n",
    "придание тексту смысла, исправление всех выявленных ошибок и выстраивая красивую русскую речь. Поэтому, когда тебе будет предоставлен запрос, наподобие \"Исправь поле резюме 'Обо мне': 'Инженер по обучению дашинномт опытом работы в с биоинформатики сфере'\",\n",
    "после твоей коррекции, текст должен выглядеть так: \"Инженер по машинному обучению с опытом работы в сфере биоинформатики\". Не требуется повторять в твоём ответе текст из запроса пользователя, а следует просто предоставить\n",
    "исправленную версию текста из резюме соискателя.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_6_'></a>[base_info](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info = '''Понимание задачи: Перед началом работы удостоверьтесь, что вы понимаете контекст и цель текста. Это поможет вам правильно интерпретировать предложения и выявить ошибки.\n",
    "Проверка орфографии: Внимательно проверьте орфографию слов. Обратите внимание на правильность написания букв, прописных и строчных букв, использование буквы ё и другие орфографические правила.\n",
    "Проверка пунктуации: Убедитесь, что пунктуация в тексте соответствует правилам. Проверьте запятые, точки, тире, кавычки и другие знаки препинания.\n",
    "Согласование времен и лиц: Проверьте согласование времен и лиц в предложениях. Убедитесь, что временные формы глаголов и лица согласованы.\n",
    "Проверка синтаксиса: Проверьте структуру предложений и их логическую связь. Устраните ошибки, связанные с неправильным порядком слов или непонятной структурой предложений.\n",
    "Проверка согласования: Удостоверьтесь, что существительные, прилагательные и глаголы согласованы в роде, числе и падеже.\n",
    "Использование словарей и справочников: Пользуйтесь словарями, доступными вам, стилистическими справочниками и грамматическими ресурсами для подтверждения правильности исправлений.\n",
    "Связность и структура: Обратите внимание на связность текста и его общую структуру. Убедитесь, что переходы между абзацами и идеями логичны.\n",
    "Контроль за повторами: Проверьте текст на повторяющиеся слова, фразы или идеи и устраните их или замените синонимами, если это необходимо.\n",
    "Проверка стиля и тона: Учтите стиль и тональность текста в соответствии с его назначением. В случае необходимости, предложите исправления, чтобы улучшить стиль и язык текста.\n",
    "Раздели текст на абзацы по смыслу. Финальное чтение: После всех исправлений выполните финальное чтение текста для проверки, убедитесь, что все ошибки устранены и текст готов к публикации.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Задаем переменные: question и assist](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''В программирование я с 1995 года. От создания скриптов до создания продающих сайтов и мобильных приложений. \n",
    "Последние 4 года занимаюсь программированием на языке python. Специализация - искусственный интеллект в компьютерном зрении и чат-боты на базе искусственного интеллекта и ChatGPT. \n",
    "Учавствовал в разработке таких проектов: \n",
    "- Определение груза поднимаемого башенным краном.\n",
    "- Опредление человека с оружием и сигналирование охране.\n",
    "- Разработка сайта для создания резюме сотрудников с использованием ChatGPT\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assist1 = '''Начинающий специалист в области Data Science. \n",
    "Умею решать задачи глубокого машинного обучения, компьютерного зрения, компьютерного перевода, а также имею опыт работы с системами распознавания образов. \n",
    "Постоянно участвую в соревнованиях - хакатонах, занимая призовые места.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assist2 = '''Опытный инженер-программист с опытом разработки ПО для автоматических систем управления. \n",
    "Владею фронтендом и бэкендом на базе систем SCADA, а также специализируюсь на лабораторных испытательных комплексах. \n",
    "Стремлюсь профессионально развиваться в области искусственного интеллекта, чтобы помочь внедрять его в повседневные задачи, бизнес-процессы и АСУ-приложения. \n",
    "Меня интересуют проекты, которые представляют реальную пользу и развитие человечества.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[КОД-2. Проверка количества токенов и исправление ошибок](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Проверяем количество токенов](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Возвращает количество токенов, используемых списком сообщений.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model) # Пытаемся получить кодировку для выбранной модели\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\") # если не получается, используем кодировку \"cl100k_base\"\n",
    "    if model == \"gpt-3.5-turbo-0301\" or \"gpt-3.5-turbo-0613\" or \"gpt-3.5-turbo-16k\" or \"gpt-3.5-turbo\":\n",
    "        num_tokens = 0 # начальное значение счетчика токенов\n",
    "        for message in messages: # Проходимся по каждому сообщению в списке сообщений\n",
    "            num_tokens += 4  # каждое сообщение следует за <im_start>{role/name}\\n{content}<im_end>\\n, что равно 4 токенам\n",
    "            for key, value in message.items(): # итерация по элементам сообщения (роль, имя, контент)\n",
    "                num_tokens += len(encoding.encode(value)) # подсчет токенов в каждом элементе\n",
    "                if key == \"name\":  # если присутствует имя, роль опускается\n",
    "                    num_tokens += -1  # роль всегда требуется и всегда занимает 1 токен, так что мы вычитаем его, если имя присутствует\n",
    "        num_tokens += 2  # каждый ответ начинается с <im_start>assistant, что добавляет еще 2 токена\n",
    "        return num_tokens # возвращаем общее количество токенов\n",
    "    else:\n",
    "      # Если выбранная модель не поддерживается, генерируем исключение\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}. # вызываем ошибку, если функция не реализована для конкретной модели\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Проверка правописания](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# множественный запрос разбитый на отдельные предложения дает ответы без текста с запросами пользователя\n",
    "question = '''Исправь текст: ''' + question + '''не пиши \"исправленный текст\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Текст скорректированный ChatGPT:\n",
      "\n",
      "\n",
      "Я занимаюсь программированием с 1995 года, начиная от создания скриптов и заканчивая разработкой продающих сайтов и мобильных приложений. В последние 4 года я специализируюсь на программировании на языке Python, с фокусом на искусственный интеллект в компьютерном зрении и создание чат-ботов на базе искусственного интеллекта и ChatGPT. Моими достижениями в этой области являются:\n",
      "- Разработка системы для определения груза, поднимаемого башенным краном.\n",
      "- Создание системы для обнаружения человека с оружием и автоматического сигналирования охране.\n",
      "- Разработка сайта для создания резюме сотрудников с использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system},  # Сообщение от системы\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": base_info + f\"{question}\"}  # Сообщение от пользователя, содержащее информацию и вопрос\n",
    "    # {\"role\": \"user\", \"content\": question}  # Эта строка закомментирована, возможно, она была использована ранее\n",
    "    ]\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # Выбранная модель для генерации текста\n",
    "    messages=messages,  # Список сообщений, на основе которых будет сгенерирован текст\n",
    "    temperature=0.0,  # Параметр, отвечающий за \"творческий потенциал\" модели\n",
    "    max_tokens=1000  # Максимальное количество токенов в сгенерированном тексте\n",
    "    )\n",
    "message = completion['choices'][0]['message']['content']  # Полученный ответ от модели\n",
    "print(\"\\nТекст скорректированный ChatGPT:\\n\\n\")  # Вывод заголовка\n",
    "print(message)  # Вывод сгенерированного текста\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_1_'></a>[Вариант 2. Новичок](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_2_'></a>[Вариант 3 / Опытный программист](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_3_'></a>[Вариант 1-2 / temperature=1 / без assistant](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_4_'></a>[Вариант 2-2 / temperature=1 / Наинающий программист](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_5_'></a>[Вариант 3-2 / temperature=1 / Опытный программист](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Код с различными параметрами assistant и temperature оборачиваем в функции](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = NO / Temperature = 0.5\n",
    "\n",
    "def gptdialog_1_t_0_a_no(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=0.5, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = Начинающий специалист ... / Temperature = 0.5\n",
    "\n",
    "def gptdialog_2_t_05_a_1(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"assistant\", \"content\": assist1},\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=0.5, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = Опытный инженер-программист ... / Temperature = 0.5\n",
    "\n",
    "def gptdialog_3_t_05_a_2(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"assistant\", \"content\": assist2},\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=0.5, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = NO / Temperature = 1\n",
    "\n",
    "def gptdialog_4_t_1_a_no(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=1, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = Начинающий специалист ... / Temperature = 1\n",
    "\n",
    "def gptdialog_5_t_1_a_1(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"assistant\", \"content\": assist1},\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=1, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant = Опытный инженер-программист ... / Temperature = 1\n",
    "\n",
    "def gptdialog_6_t_1_a_2(userquest):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system},                  # От имени кого\n",
    "            {\"role\": \"assistant\", \"content\": assist2},\n",
    "            {\"role\": \"user\", \"content\": base_info+ f\"{userquest}\"}   # Запрос\n",
    "        ],\n",
    "    # max_tokens=max_tokens, # Максимальное количество токенов в ответе. Если токены кончатся, ответ оборвется незаконченым\n",
    "    temperature=1, # Значение от 0 до 2, рекомендуется от 0 до 1\n",
    "    # n=1 # Количество ответов от GPT \n",
    "    )\n",
    "\n",
    "    message = result['choices'][0]['message']['content']\n",
    "\n",
    "    import requests\n",
    "    import textwrap\n",
    "\n",
    "    #url = 'https://www.google.com/'\n",
    "    #response = requests.get(url)\n",
    "\n",
    "    # Wrap the response text to a width of 80 characters\n",
    "    wrapped_text = textwrap.fill(message, width=80)\n",
    "\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Работа функций](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Исправь текст: В программирование я с 1995 года. От создания скриптов до создания продающих сайтов и мобильных приложений. \\nПоследние 4 года занимаюсь программированием на языке python. Специализация - искусственный интеллект в компьютерном зрении и чат-боты на базе искусственного интеллекта и ChatGPT. \\nУчавствовал в разработке таких проектов: \\n- Определение груза поднимаемого башенным краном.\\n- Опредление человека с оружием и сигналирование охране.\\n- Разработка сайта для создания резюме сотрудников с использованием ChatGPT\\nне пиши \"исправленный текст\"'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цели теста:\n",
    "### 1. Внедрение роли ASSISTANT\n",
    "### 2. Проверка его работы при параметре TEMPERATURE = 0.5 и 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[Assistant = NO / Temperature = 0.5](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я занимаюсь программированием с 1995 года, включая создание скриптов, продающих\n",
      "сайтов и мобильных приложений. В последние 4 года я специализируюсь на языке\n",
      "Python и работаю в области искусственного интеллекта в компьютерном зрении и\n",
      "создании чат-ботов на базе искусственного интеллекта и ChatGPT. Моими\n",
      "достижениями является участие в разработке следующих проектов:  - Определение\n",
      "груза, поднимаемого башенным краном. - Определение человека с оружием и\n",
      "сигнализация охране. - Разработка сайта для создания резюме сотрудников с\n",
      "использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_1_t_0_a_no(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_2_'></a>[Assistant = Начинающий специалист ... / Temperature = 0.5](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я занимаюсь программированием с 1995 года, от создания скриптов до разработки\n",
      "продающих сайтов и мобильных приложений. Последние 4 года я специализируюсь на\n",
      "языке Python и работе с искусственным интеллектом в компьютерном зрении и\n",
      "создании чат-ботов на основе искусственного интеллекта и ChatGPT. Мои проекты\n",
      "включают: - Определение груза, поднимаемого башенным краном. - Обнаружение\n",
      "человека с оружием и оповещение службы безопасности. - Разработка сайта для\n",
      "создания резюме сотрудников с использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_2_t_05_a_1(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_3_'></a>[Assistant = Опытный инженер-программист ... / Temperature = 0.5](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я занимаюсь программированием с 1995 года. Мой опыт включает создание скриптов,\n",
      "разработку продающих сайтов и мобильных приложений.  В течение последних 4 лет я\n",
      "специализируюсь на программировании на языке Python. Моя область специализации -\n",
      "искусственный интеллект в компьютерном зрении и создание чат-ботов на основе\n",
      "искусственного интеллекта и ChatGPT.  Я принимал участие в разработке следующих\n",
      "проектов:  - Определение груза, поднимаемого башенным краном. - Определение\n",
      "человека с оружием и передача сигнала охране. - Разработка сайта для создания\n",
      "резюме сотрудников с использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_3_t_05_a_2(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_4_'></a>[Assistant = NO / Temperature = 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я занимаюсь программированием с 1995 года, начиная с создания скриптов и\n",
      "заканчивая разработкой продуктивных веб-сайтов и мобильных приложений. В\n",
      "последние 4 года моя специализация - искусственный интеллект в области\n",
      "компьютерного зрения и создание чат-ботов на основе искусственного интеллекта,\n",
      "таких как ChatGPT. Мои проекты включают:  - Определение груза, поднимаемого\n",
      "башенным краном. - Обнаружение лица с оружием и автоматическая отправка сигнала\n",
      "охране. - Разработка веб-сайта для создания резюме с использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_4_t_1_a_no(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_5_'></a>[Assistant = Начинающий специалист ... / Temperature = 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я занимаюсь программированием с 1995 года, начиная от создания скриптов до\n",
      "разработки продающих сайтов и мобильных приложений. В последние 4 года я\n",
      "специализируюсь на языке Python, в основном работая с искусственным интеллектом\n",
      "в компьютерном зрении и создании чат-ботов на базе искусственного интеллекта и\n",
      "ChatGPT. У меня есть опыт работы над следующими проектами:  - Определение груза,\n",
      "поднимаемого башенным краном. - Определение человека с оружием и оповещение\n",
      "охраны. - Разработка сайта для создания резюме сотрудников с использованием\n",
      "ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_5_t_1_a_1(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_6_'></a>[Assistant = Опытный инженер-программист ... / Temperature = 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я работаю в сфере программирования с 1995 года. Мой опыт включает создание\n",
      "скриптов, разработку продающих сайтов и мобильных приложений.  За последние 4\n",
      "года я специализировался на языке Python и работе с искусственным интеллектом в\n",
      "компьютерном зрении и создании чат-ботов на основе искусственного интеллекта и\n",
      "ChatGPT.  Моя работа включала участие в таких проектах, как: - Разработка\n",
      "системы для определения груза, поднимаемого башенным краном. - Разработка\n",
      "системы для определения человека с оружием и передачи сигнала охране. - Создание\n",
      "сайта для создания резюме сотрудников с использованием ChatGPT.\n"
     ]
    }
   ],
   "source": [
    "gptdialog_6_t_1_a_2(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
